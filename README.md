# ArduPilot SITL + Gazebo + DroneKit + YOLOv8 Visual Guidance

This project demonstrates a **vision-based object detection and navigation system** for a drone using **ArduPilot**, **Gazebo**, and **DroneKit**.  
The drone uses a **YOLOv8** model and an onboard camera feed to detect a target box on the ground and autonomously fly and land on it.

# Libraries Used

| Component              | Description                                      |
| ---------------------- | ------------------------------------------------ |
| **ArduPilot**          | Flight control firmware                          |
| **Gazebo Harmonic**    | Physics and 3D visualization simulator           |
| **DroneKit-Python**    | Python API to control ArduPilot via MAVLink      |
| **Ultralytics YOLOv8** | Object detection framework                       |
| **OpenCV**             | Video capture and image processing               |
| **Ubuntu 22.04**       | Video capture and image processing               |
| **Python 3.8+**        | Core runtime environment                         |

# Prerequisities Installation

## 1ï¸âƒ£ Install ArduPilot and SITL
```bash
git clone https://github.com/ArduPilot/ardupilot.git
cd ardupilot
Tools/environment_install/install-prereqs-ubuntu.sh -y
. ~/.profile
```

## 2ï¸âƒ£ Install Gazebo and ArduPilot plugin
```bash
sudo apt install gazebo libgazebo-dev
git clone https://github.com/ArduPilot/ardupilot_gazebo.git
cd ardupilot_gazebo
mkdir build && cd build
cmake ..
make -j4
sudo make install
```

## 3ï¸âƒ£ Python dependencies
```bash
pip install dronekit pymavlink opencv-python ultralytics numpy
```

# Project Structure
```bash
ğŸ“¦ Ardupilot_VisualGuidance
â”œâ”€â”€ Ardupilot_Gazebo_SITL.py       # Main control script
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ data.yaml                      # YOLO configuration file
â”œâ”€â”€ models/
â”‚   â””â”€â”€ box_target/                # Gazebo model of the target box
â”‚       â”œâ”€â”€ model.config
â”‚       â””â”€â”€ model.sdf
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ detect/
â”‚       â””â”€â”€ train/
â”‚            â””â”€â”€ weights/
â”‚               â””â”€â”€ best.pt       # YOLOv8 trained weights
â”‚       â””â”€â”€ val  

```

# Running a simulation

## 1ï¸âƒ£ Start ArduPilot SITL
```bash
sim_vehicle.py -v ArduCopter -f gazebo-iris --console --map
```

## 2ï¸âƒ£ Launch Gazebo with box model
```bash
gz sim ~/ardupilot_gazebo/worlds/iris_arducopter_runway.sdf
```

## 3ï¸âƒ£ Run the Python script
```bash
python3 Ardupilot_Gazebo_SITL.py
```

# How It Works

The drone takes off to a defined altitude and flies to a pre-defined waypoint.

YOLOv8 runs inference on each frame from the camera feed.

When the box is detected,

The pixel offset from the image center is converted to real-world meters.

The drone flies toward the box using position or velocity control.

If detection is lost,

The drone hovers or performs a slow search yaw.

After a configurable timeout, it returns to launch (RTL).

# Author

Keerthana Radhakrishnan

LinkedIn: www.linkedin.com/in/keerthanaradhakrishnan

